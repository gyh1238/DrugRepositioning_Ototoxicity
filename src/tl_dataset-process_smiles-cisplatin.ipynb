{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [02:12:53] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import deepchem as dc\n",
    "import pandas as pd\n",
    "from rdkit import Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import deepchem as dc\n",
    "from deepchem.molnet.load_function.molnet_loader import TransformerGenerator, _MolnetLoader\n",
    "from deepchem.data import Dataset\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "#TASKS = [\n",
    "#    'amg', 'cisplatin'\n",
    "#]\n",
    "TASKS = [\n",
    "    'cisplatin'\n",
    "]\n",
    "\n",
    "\n",
    "class _DataLoader(_MolnetLoader):\n",
    "\n",
    "    def create_dataset(self) -> Dataset:\n",
    "        dataset_file = os.path.join(self.data_dir, \"combined_cisplatin_data.csv.gz\")\n",
    "        loader = dc.data.CSVLoader(\n",
    "            tasks=self.tasks, feature_field=\"smiles\", featurizer=self.featurizer)\n",
    "        return loader.create_dataset(dataset_file, shard_size=8192)\n",
    "\n",
    "\n",
    "def load_data(\n",
    "        featurizer: Union[dc.feat.Featurizer, str] = 'ECFP',\n",
    "        splitter: Union[dc.splits.Splitter, str, None] = 'scaffold',\n",
    "        transformers: List[Union[TransformerGenerator, str]] = ['balancing'],\n",
    "        reload: bool = True,\n",
    "        data_dir: Optional[str] = None,\n",
    "        save_dir: Optional[str] = None,\n",
    "        **kwargs\n",
    "    ) -> Tuple[List[str], Tuple[Dataset, ...], List[dc.trans.Transformer]]:\n",
    "    loader = _DataLoader(featurizer, splitter, transformers, TASKS,\n",
    "                        data_dir, save_dir, **kwargs)\n",
    "    return loader.load_dataset('combined', reload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to featurize datapoint 590, [Hg+2]. Appending empty array\n",
      "Exception message: zero-size array to reduction operation maximum which has no identity\n",
      "Failed to featurize datapoint 597, [Se]. Appending empty array\n",
      "Exception message: zero-size array to reduction operation maximum which has no identity\n",
      "/home/yjchoi/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "from featurizer import MolGraphConvFeaturizer\n",
    "\n",
    "featurizer = MolGraphConvFeaturizer(\n",
    "    use_edges=True, use_chirality=True, use_partial_charge=True\n",
    ")\n",
    "\n",
    "splitter = dc.splits.RandomStratifiedSplitter()\n",
    "\n",
    "combined_tasks, datasets, transformers = load_data(\n",
    "    featurizer=featurizer, splitter=splitter, \n",
    "    data_dir='data/combined/cisplatin/', save_dir='data/combined/cisplatin/'\n",
    ")\n",
    "train_dataset, valid_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/val/test split: 490/61/61\n",
      "num_node_features: 79\n",
      "num_edge_features: 12\n"
     ]
    }
   ],
   "source": [
    "print('train/val/test split: {}/{}/{}'.format(len(train_dataset), len(valid_dataset), len(test_dataset)))\n",
    "print('num_node_features: {}'.format(train_dataset.X[0].num_node_features))\n",
    "print('num_edge_features: {}'.format(train_dataset.X[0].num_edge_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.utils.save_dataset_to_disk('data/combined/cisplatin/', train_dataset, valid_dataset, test_dataset, transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
